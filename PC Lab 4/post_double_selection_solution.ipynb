{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Post-Double-Selection Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: [Anthony Strittmatter](https://www.anthonystrittmatter.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Job Corps is the largest U.S. labor market program targeting disadvantaged youths. It  provides  academic, vocational, and  social training, as well as health care counseling and job search assistance, for an average duration of eight to nine months. Mathematica Policy Research carried out a randomized experiment with the Job Corps. About 60% of the experimental participants were randomly selected to receive an offer to participatein the Job Corps. Out of these, 73% joined the Job Corps program and actually started to participate after an average duration of 1.4 months. The remaining experimental \n",
    "participants were assigned to the control group. Control group members were not eligible for the Job Corps programs for three years following randomization (approximately 1% participated anyway).\n",
    "\n",
    "We estimate the effects of actually participating in the Job Corps on earnings fours years after the randomization. The experimental Job Corps data job_corps.csv contains 10'516 observations.\n",
    "\n",
    "**Variable list :** \n",
    "\n",
    "* **EARNY4**: Earnings per week in Year 4\n",
    "* **assignment**: Dummy for randomized offer to join Job Corps\n",
    "* **participation**: Dummy for actual participation in Job Corps\n",
    "* **female**: Dummy for females\n",
    "* **age1**: Aged between 16-17 years\n",
    "* **age2**: Aged between 18-19 years\n",
    "* **age3**: Aged between 20-24 years\n",
    "* **ed_06**: 0-6 months education program in last year prior experiment\n",
    "* **ed_612**: 6-12 months education program in last year pror experiment\n",
    "* **hs_ged**: High school or GED credential (general educational development test)\n",
    "* **white**: Dummy for white ethnicity\n",
    "* **black**: Dummy for African-American ethnicity\n",
    "* **hisp**: Dummy for Hispanic ethnicity\n",
    "* **oth_eth**: Dummy for other ethnicity\n",
    "* **haschld**: Dummy for parents\n",
    "* **livespou**: Lives with spouse or partner\n",
    "* **everwork**: Ever had job for two weeks or more\n",
    "* **yr_work**: Worked in year prior to random assignment\n",
    "* **currjob**: Has job at random assignment\n",
    "* **job0_3**: Below 3 months employed in last year\n",
    "* **job3_9**: 3-9 months employed in last year\n",
    "* **job9_12**: 9-12 months employed in last year\n",
    "* **earn1**: Yearly earnings less than \\$1'000 prior experiment \n",
    "* **earn2**: Yearly earnings \\$1'000-5'000 prior experiment \n",
    "* **earn3**: Yearly earnings \\$5'000-10'000 prior experiment \n",
    "* **earn4**: Yearly earnings above \\$10'000 prior experiment \n",
    "* **badhlth**: Dummy for bad health\n",
    "* **welf_kid**: Family on welfare when growing up\n",
    "* **got_fs**: Received food stamps in last year\n",
    "* **publich**: Public or rent-subsidized housing\n",
    "* **got_afdc**: Received AFDC (aid for families with dependent children) in last year\n",
    "* **harduse**: Used hard drugs in last year\n",
    "* **potuse**: Smoked marijuana in last year\n",
    "* **evarrst**: Ever arrested dummy\n",
    "* **pmsa**: Lives in PMSA (primary metropolitan statistical area)\n",
    "* **msa**: Lives in MSA (metropolitan statistical area)\n",
    "\n",
    "Load the data \"job_corps.csv\". If not already installed, install the packages *hdm*, *glmnet*, *tidyverse*, *caret*, *lmtest*, *sandwich*, and *fBasics*.\n",
    "\n",
    "Draw a random subsample of 3'000 observations. We need a smaller data set in this tutorial, because otherwise the computation time on the server would be too long. In reality you would use the entire data.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages and the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'fBasics' was built under R version 3.6.3\"Loading required package: timeDate\n",
      "Loading required package: timeSeries\n",
      "Warning message:\n",
      "\"package 'timeSeries' was built under R version 3.6.3\"Warning message:\n",
      "\"package 'tidyverse' was built under R version 3.6.3\"-- Attaching packages --------------------------------------- tidyverse 1.3.0 --\n",
      "v ggplot2 3.3.3     v purrr   0.3.4\n",
      "v tibble  3.0.6     v dplyr   1.0.4\n",
      "v tidyr   1.1.2     v stringr 1.4.0\n",
      "v readr   1.3.1     v forcats 0.4.0\n",
      "Warning message:\n",
      "\"package 'ggplot2' was built under R version 3.6.3\"Warning message:\n",
      "\"package 'tibble' was built under R version 3.6.3\"Warning message:\n",
      "\"package 'tidyr' was built under R version 3.6.3\"Warning message:\n",
      "\"package 'purrr' was built under R version 3.6.3\"Warning message:\n",
      "\"package 'dplyr' was built under R version 3.6.3\"-- Conflicts ------------------------------------------ tidyverse_conflicts() --\n",
      "x dplyr::filter() masks timeSeries::filter(), stats::filter()\n",
      "x dplyr::lag()    masks timeSeries::lag(), stats::lag()\n",
      "Loading required package: lattice\n",
      "\n",
      "Attaching package: 'caret'\n",
      "\n",
      "The following object is masked from 'package:purrr':\n",
      "\n",
      "    lift\n",
      "\n",
      "Warning message:\n",
      "\"package 'lmtest' was built under R version 3.6.3\"Loading required package: zoo\n",
      "\n",
      "Attaching package: 'zoo'\n",
      "\n",
      "The following object is masked from 'package:timeSeries':\n",
      "\n",
      "    time<-\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    as.Date, as.Date.numeric\n",
      "\n",
      "Warning message:\n",
      "\"package 'sandwich' was built under R version 3.6.3\"Warning message:\n",
      "\"package 'hdm' was built under R version 3.6.3\"Warning message:\n",
      "\"package 'glmnet' was built under R version 3.6.3\"Loading required package: Matrix\n",
      "\n",
      "Attaching package: 'Matrix'\n",
      "\n",
      "The following objects are masked from 'package:tidyr':\n",
      "\n",
      "    expand, pack, unpack\n",
      "\n",
      "Loaded glmnet 4.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"All packages successfully installed and loaded.\"\n",
      "[1] \"Data successfully loaded.\"\n"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "########################  Load Packages and the Data  ########################\n",
    "##############################################################################\n",
    "\n",
    "### Load the packages  \n",
    "library(fBasics)     # use for descriptive statistics\n",
    "library(tidyverse)   # use for handling data\n",
    "library(caret)       # use for handling data\n",
    "library(lmtest)      # use for heteroscedasticity robust standard errors\n",
    "library(sandwich)    # use for heteroscedasticity robust standard errors\n",
    "library(hdm)         # use for Lasso and Post-Double-Selection\n",
    "library(glmnet)      # use for lasso and Elastic Net regularized Generalized Linear Models\n",
    "options(warn=-1)     # supress warnings\n",
    "\n",
    "print('All packages successfully installed and loaded.')\n",
    "\n",
    "### Load the Data\n",
    "set.seed(12345678) \n",
    "df <- read.csv(\"job_corps.csv\",header=TRUE, sep=\",\") # load data from csv-file\n",
    "df <- df[sample(c(1:nrow(df)), size=3000, replace =F),] # Select a random subsample of 3000 observations\n",
    "print('Data successfully loaded.')\n",
    "\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Mean  Stdev Minimum Maximum nobs\n",
      "EARNY4        207.42 205.42       0 2357.74 3000\n",
      "assignment      0.60   0.49       0    1.00 3000\n",
      "participation   0.44   0.50       0    1.00 3000\n",
      "female          0.43   0.49       0    1.00 3000\n",
      "age_1           0.41   0.49       0    1.00 3000\n",
      "age_2           0.32   0.46       0    1.00 3000\n",
      "age_3           0.28   0.45       0    1.00 3000\n",
      "ed0_6           0.26   0.44       0    1.00 3000\n",
      "ed6_12          0.37   0.48       0    1.00 3000\n",
      "hs_ged          0.25   0.43       0    1.00 3000\n",
      "white           0.26   0.44       0    1.00 3000\n",
      "black           0.49   0.50       0    1.00 3000\n",
      "hisp            0.17   0.38       0    1.00 3000\n",
      "oth_eth         0.07   0.26       0    1.00 3000\n",
      "haschld         0.21   0.40       0    1.00 3000\n",
      "livespou        0.07   0.25       0    1.00 3000\n",
      "everwork        0.80   0.40       0    1.00 3000\n",
      "yr_work         0.64   0.48       0    1.00 3000\n",
      "currjob         0.20   0.40       0    1.00 3000\n",
      "job0_3          0.22   0.42       0    1.00 3000\n",
      "job3_9          0.29   0.45       0    1.00 3000\n",
      "job9_12         0.21   0.41       0    1.00 3000\n",
      "earn1           0.11   0.31       0    1.00 3000\n",
      "earn2           0.27   0.44       0    1.00 3000\n",
      "earn3           0.14   0.34       0    1.00 3000\n",
      "earn4           0.07   0.25       0    1.00 3000\n",
      "badhlth         0.13   0.34       0    1.00 3000\n",
      "welf_kid        0.20   0.40       0    1.00 3000\n",
      "got_fs          0.44   0.50       0    1.00 3000\n",
      "publich         0.22   0.42       0    1.00 3000\n",
      "got_afdc        0.32   0.46       0    1.00 3000\n",
      "harduse         0.06   0.23       0    1.00 3000\n",
      "potuse          0.25   0.43       0    1.00 3000\n",
      "evarrst         0.24   0.43       0    1.00 3000\n",
      "pmsa            0.33   0.47       0    1.00 3000\n",
      "msa             0.46   0.50       0    1.00 3000\n"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "########################  Descriptive Statistics  ############################\n",
    "##############################################################################\n",
    "\n",
    "## Table with Descriptive Statistics \n",
    "desc <- fBasics::basicStats(df) %>% t() %>% as.data.frame() %>% \n",
    "          select(Mean, Stdev, Minimum, Maximum, nobs)\n",
    "print(round(desc, digits=2))\n",
    "\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missings (see last column *nobs*). All variables (excluding earnings) are binary dummies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate OLS Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to estimate the causal effect of participation in Job Corps on earnings. For this purpose, we estimate the univariate linear regression model,\n",
    "\n",
    "\\begin{equation*}\n",
    "EARNY4 = \\gamma + \\delta \\cdot participation +u.\n",
    "\\end{equation*}\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "1. How large is the effect of participation in Job Corps on earnings?\n",
    "2. What is the main assumtpion we have to make to interprete this effect in a causal way?\n",
    "3. How credible is the identifying assumption in this application?\n",
    "4. Can we improve the credibility of the identification strategy using observable exogeneous charactersitics $X$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = EARNY4 ~ participation, data = df)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-214.40 -175.29  -26.27   98.82 2155.83 \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)    201.904      5.018  40.239   <2e-16 ***\n",
       "participation   12.497      7.550   1.655    0.098 .  \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 205.4 on 2998 degrees of freedom\n",
       "Multiple R-squared:  0.000913,\tAdjusted R-squared:  0.0005798 \n",
       "F-statistic:  2.74 on 1 and 2998 DF,  p-value: 0.09799\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Estimate Std. Error   Pr(>|t|) \n",
      "     12.50       7.55       0.10 \n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "########################  Univariate OLS Regression #####################\n",
    "#########################################################################\n",
    "\n",
    "## Univariate OLS\n",
    "ols1 <- lm(EARNY4 ~ participation, data = df)\n",
    "summary(ols1)\n",
    "\n",
    "## Store results\n",
    "results <- as.matrix(coef(summary(ols1))[2, c(\"Estimate\", \"Std. Error\", \"Pr(>|t|)\")])\n",
    "\n",
    "# Prepare matrix to store results\n",
    "res <- matrix(NA,nrow=3,ncol=5)\n",
    "colnames(res) <- c(\"Univariate OLS\", \"Multivariate OLS1\", \"Multivariate OLS2\",\n",
    "                   \"Multivariate OLS3\", \"Multivariate OLS4\")\n",
    "rownames(res) <- rownames(results)\n",
    "res[,1] <- results\n",
    "\n",
    "print(round(res[,1], digits=2))\n",
    "\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers:**\n",
    "\n",
    "1. The estimation results suggest that participation in Job Corps increased weekly earnings by 12.50 Dollars four years after the experiment.\n",
    "2. The main identifying assumptions is the error term $u$ is independent of $participation$, $E[u|participation =1] = E[u|participation =0]$. Additionally, we have to impose the stable unit treatment valua assumption (SUTVA) and common support. The SUTVA excludes spillover and general equilibrium effects. The common support assumption can be tested and is valid in this application. Having said this, both assumptions are not the focus of this tutorial.\n",
    "3. The offer to participate in Job Corps was randomized in the experiment. However, actual participation was not randomized. Individuals could self-select based on preferences or expected returns to training into participation in the Job Corps program. This could create selection bias. Accordingly, the main identifying assumption is not credible. For example, those individuals with good labor market persectives could be over-represented among the participants. This could lead to a negative selection bias,  if the effect of participation is negatively corrleated with labor market perspectives.\n",
    "4. We could increase the credibility of the identification strategy by conditioning on exogeneous confounders $X$. This are observable characteristics which have a joint impact on earnings and the probability to participate in the Job Corps program. We could relax the aformentioned independence assumption to $E[u|participation =1,X] = E[u|participation =0,X]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate OLS Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we estimate the multivariate linear regression model,\n",
    "\n",
    "\\begin{equation*}\n",
    "EARNY4 = \\gamma + \\delta \\cdot participation + \\beta \\cdot X + u.\n",
    "\\end{equation*}\n",
    "\n",
    "The main identifying assumption $E[u|participation =1,X] = E[u|participation =0,X]$ is weaker than for the univariate model. But we have to assume additionally effect homogeneity, i.e., the effect of participation in Job Corps on earnings is equal for all individuals. We could relax this assumption by including interaction terms between $participation$ and $X$, but this would make the model more complicated and difficult to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION: HOW TO SELECT THE CONTROL VARIABLES $X$?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas to select control variables:\n",
    "\n",
    "1. Standardized differences\n",
    "2. Domain knowledge\n",
    "3. Kitchen sink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Idea 1 (Standardized Differences):** Compare the difference in the observable characteristics between the groups of participants and non-participants. Characteristics which differ greatly between the two groups appear to be important control variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         D=1 Mean D=1 Std.Dev. D=0 Mean D=0 Std.Dev. Std.Diff.\n",
      "female       0.45         0.50     0.41         0.49      7.19\n",
      "age_1        0.44         0.50     0.38         0.49     11.82\n",
      "age_2        0.31         0.46     0.32         0.47      3.28\n",
      "age_3        0.26         0.44     0.30         0.46      9.58\n",
      "ed0_6        0.24         0.43     0.27         0.44      6.50\n",
      "ed6_12       0.39         0.49     0.35         0.48      8.71\n",
      "hs_ged       0.23         0.42     0.27         0.44      7.42\n",
      "white        0.26         0.44     0.27         0.44      3.45\n",
      "black        0.50         0.50     0.48         0.50      4.04\n",
      "hisp         0.17         0.37     0.18         0.38      2.85\n",
      "oth_eth      0.08         0.27     0.07         0.26      2.22\n",
      "haschld      0.20         0.40     0.21         0.41      4.82\n",
      "livespou     0.05         0.22     0.08         0.27     11.38\n",
      "everwork     0.79         0.41     0.81         0.39      4.60\n",
      "yr_work      0.63         0.48     0.65         0.48      4.72\n",
      "currjob      0.20         0.40     0.20         0.40      1.01\n",
      "job0_3       0.22         0.42     0.22         0.41      0.24\n",
      "job3_9       0.29         0.46     0.29         0.45      1.18\n",
      "job9_12      0.19         0.40     0.23         0.42      8.03\n",
      "earn1        0.11         0.31     0.11         0.32      1.92\n",
      "earn2        0.28         0.45     0.26         0.44      5.01\n",
      "earn3        0.13         0.33     0.14         0.35      3.92\n",
      "earn4        0.05         0.23     0.07         0.26      8.26\n",
      "badhlth      0.13         0.34     0.14         0.34      2.60\n",
      "welf_kid     0.21         0.41     0.19         0.39      6.25\n",
      "got_fs       0.44         0.50     0.44         0.50      0.21\n",
      "publich      0.25         0.43     0.20         0.40     10.71\n",
      "got_afdc     0.33         0.47     0.31         0.46      4.86\n",
      "harduse      0.06         0.23     0.06         0.24      1.65\n",
      "potuse       0.26         0.44     0.24         0.43      3.76\n",
      "evarrst      0.23         0.42     0.25         0.43      5.36\n",
      "pmsa         0.32         0.47     0.34         0.47      4.33\n",
      "msa          0.46         0.50     0.46         0.50      1.25\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "########################  Standardized Differences #####################\n",
    "########################################################################\n",
    "\n",
    "## Means and standard deviations for the participants (D=1)\n",
    "desc_1 <- fBasics::basicStats(df[df$participation==1,]) %>% t() %>% as.data.frame() %>% select(Mean, Stdev)\n",
    "\n",
    "## Means and standard deviations for the non-participants (D=0)\n",
    "desc_0 <- fBasics::basicStats(df[df$participation==0,]) %>% t() %>% as.data.frame() %>% select(Mean, Stdev)\n",
    "\n",
    "# Make table and add standardized differences\n",
    "desc <- cbind(desc_1[-c(1:3),],desc_0[-c(1:3),], \n",
    "        100*abs(desc_1[-c(1:3),1]-desc_0[-c(1:3),1])/sqrt(0.5*(desc_1[-c(1:3),2]^2+desc_0[-c(1:3),2]^2)))\n",
    "colnames(desc) <- c(\"D=1 Mean\", \"D=1 Std.Dev.\", \"D=0 Mean\", \"D=0 Std.Dev.\", \"Std.Diff.\")\n",
    "print(round(desc, digits=2))\n",
    "\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standardized differences ($SD$) are defined as\n",
    "\n",
    "$SD = 100 \\displaystyle \\cdot \\frac{|\\bar{X}_1 - \\bar{X}_0|}{\\sqrt{1/2 \\cdot (\\sigma_{X1}^2+\\sigma_{X0}^2)}}$\n",
    "\n",
    "where $\\bar{X}_1$ and $\\bar{X}_0$ are the means and $\\sigma_{X1}$ and $\\sigma_{X0}$ the standard deviations in the groups of participants and non-participants, respectively. Large standardized differences indicate a large inbalance between the characteristics of participants and non-participants.\n",
    "\n",
    "\n",
    "We observe that older people, individuals who live with their spouse are less likely to participate in Job Corps. Living in a public or rent-subsidized appartment is associated with a higher participation probability. Accordingly, this might be important confounders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = EARNY4 ~ participation + age_1 + age_3 + livespou + \n",
       "    publich, data = df)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-255.82 -162.07  -22.83   96.51 2145.45 \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)    212.288      7.682  27.635  < 2e-16 ***\n",
       "participation   16.291      7.521   2.166  0.03039 *  \n",
       "age_1          -21.148      8.869  -2.384  0.01717 *  \n",
       "age_3           27.240      9.703   2.807  0.00503 ** \n",
       "livespou       -19.751     15.122  -1.306  0.19161    \n",
       "publich        -43.720      8.949  -4.885 1.09e-06 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 203.7 on 2994 degrees of freedom\n",
       "Multiple R-squared:  0.01822,\tAdjusted R-squared:  0.01658 \n",
       "F-statistic: 11.11 on 5 and 2994 DF,  p-value: 1.253e-10\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Univariate OLS Multivariate OLS1\n",
      "Estimate            12.50             16.29\n",
      "Std. Error           7.55              7.52\n",
      "Pr(>|t|)             0.10              0.03\n",
      "[1] \"Relative change in the estimated effect: 30.4%\"\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "########################  Multivariate OLS Regression ###################\n",
    "#########################################################################\n",
    "\n",
    "## Multivariate OLS\n",
    "ols2 <- lm(EARNY4 ~ participation + age_1 + age_3 + livespou + publich, data = df)\n",
    "summary(ols2)\n",
    "# Question: Why do we omit age_2?\n",
    "\n",
    "## Store results\n",
    "results <- as.matrix(coef(summary(ols2))[2, c(\"Estimate\", \"Std. Error\", \"Pr(>|t|)\")])\n",
    "res[,2] <- results\n",
    "print(round(res[,c(1:2)], digits=2))\n",
    "\n",
    "## Relative change in the estimated effect\n",
    "print(paste0(\"Relative change in the estimated effect: \",round(100*(res[1,2]-res[1,1])/res[1,1], digits=1),\"%\"))\n",
    "\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When controlling for age, living together with spouse, and public/subsidized housing, the estimated effect increases by 30\\%. Participation in Job Corps increases earnings by 16.29 Dollars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Idea 2 (Domain Knowledge):** We can select the control variables $X$ using economic theory, domain knowledge, or intuition. For example, Job Corp participants usually live on a campus during the program participation. Accordingly, parents might have a lower participation probability, because it is difficult to live together with a child on the campus. Furthermore, the effect of having a child (*haschld*) on the participation probability might might be differential for mothers and fathers. Accrodingly, the interaction between gender and children (*haschld*female*) might be relevant as well.\n",
    "\n",
    "Please specify an alternative model specification below (replace *???*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = EARNY4 ~ participation + age_1 + age_3 + haschld * \n",
       "    female + livespou + publich, data = df)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-293.97 -146.53  -23.17   94.00 2130.05 \n",
       "\n",
       "Coefficients:\n",
       "               Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)     243.084      8.269  29.399  < 2e-16 ***\n",
       "participation    19.161      7.410   2.586  0.00976 ** \n",
       "age_1           -26.722      8.772  -3.046  0.00234 ** \n",
       "age_3            31.725      9.717   3.265  0.00111 ** \n",
       "haschld         -15.397     16.685  -0.923  0.35617    \n",
       "female          -71.551      8.625  -8.296  < 2e-16 ***\n",
       "livespou         -6.716     15.375  -0.437  0.66226    \n",
       "publich         -37.487      8.845  -4.238 2.32e-05 ***\n",
       "haschld:female    3.083     19.978   0.154  0.87735    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 200.5 on 2991 degrees of freedom\n",
       "Multiple R-squared:  0.04991,\tAdjusted R-squared:  0.04736 \n",
       "F-statistic: 19.64 on 8 and 2991 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Univariate OLS Multivariate OLS1 Multivariate OLS2\n",
      "Estimate            12.50             16.29             19.16\n",
      "Std. Error           7.55              7.52              7.41\n",
      "Pr(>|t|)             0.10              0.03              0.01\n",
      "[1] \"Relative change in the estimated effect: 17.6%\"\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "\n",
    "## Multivariate OLS\n",
    "ols3 <- lm(EARNY4 ~ participation + age_1 + age_3 + haschld*female + livespou  + publich, data = df)\n",
    "summary(ols3)\n",
    "\n",
    "## Store results\n",
    "results <- as.matrix(coef(summary(ols3))[2, c(\"Estimate\", \"Std. Error\", \"Pr(>|t|)\")])\n",
    "res[,3] <- results\n",
    "print(round(res[,c(1:3)], digits=2))\n",
    "\n",
    "## Relative change in the estimated effect\n",
    "print(paste0(\"Relative change in the estimated effect: \",round(100*(res[1,3]-res[1,2])/res[1,2], digits=1),\"%\"))\n",
    "\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated effect of participation on earnings increases by 17.6\\% to 19.16 Dollars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Idea 3 (Kitchen Sink):** Based on our previous results, we could argue that it is best to control for everything available (brute force). This includes all exogeneous baseline characteristics as well as interaction terms.\n",
    "\n",
    "We generate all possible interaction terms. We merge the baseline characteristics and interaction terms. Afterwards, we eliminate interaction terms with a correlation above 0.8 to avoid multicolinearity problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Maximm number of interaction terms: 465\"\n",
      "[1] \"Total number of control variables: 420\"\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "\n",
    "## Generate first-order interactions between all control variables\n",
    "interactions <- t(apply(df[,-c(1,2,3,6,11)], 1, combn, 2, prod))\n",
    "colnames(interactions) <- paste(\"Inter.V\", combn(1:ncol(df[,-c(1,2,3,6,11)]), 2, paste, collapse=\"V\"), sep=\"\")\n",
    "print(paste0(\"Maximm number of interaction terms: \", ncol(interactions)))\n",
    "\n",
    "## Merge basline characteristics with interaction terms\n",
    "df_merge <- as.data.frame(cbind(df[,-c(1,2,3,6,11)], interactions))\n",
    "\n",
    "## Eliminate collinear variables\n",
    "df2 = cor(df_merge)\n",
    "df2[is.na(df2)] <- 1\n",
    "hc = findCorrelation(df2, cutoff=0.8) # putt any value as a \"cutoff\" \n",
    "hc = sort(hc)\n",
    "df_int = cbind(df[,c(1,3)],df_merge[,-c(hc)])\n",
    "print(paste0(\"Total number of control variables: \", ncol(df_int)-2))\n",
    "\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we estimate a linear OLS regression with all possible baseline characteristics and interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Univariate OLS Multivariate OLS1 Multivariate OLS2 Multivariate OLS3\n",
      "Estimate            12.50             16.29             19.16             23.75\n",
      "Std. Error           7.55              7.52              7.41              7.56\n",
      "Pr(>|t|)             0.10              0.03              0.01              0.00\n",
      "[1] \"Relative change in the estimated effect: 24%\"\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "\n",
    "## Multivariate OLS with all baseline characteristics and interaction terms\n",
    "ols4 <- lm(EARNY4 ~ ., data = df_int)\n",
    "\n",
    "## Store results\n",
    "results <- as.matrix(coef(summary(ols4))[2, c(\"Estimate\", \"Std. Error\", \"Pr(>|t|)\")])\n",
    "res[,4] <- results\n",
    "print(round(res[,c(1:4)], digits=2))\n",
    "\n",
    "## Relative change in the estimated effect\n",
    "print(paste0(\"Relative change in the estimated effect: \",round(100*(res[1,4]-res[1,3])/res[1,3], digits=1),\"%\"))\n",
    "\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated effect of Job Corp participation on earnings increases by another 24\\% to 23.75 Dollars. Compared to the univariate OLS results, the effect increases by 90\\%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To bring it to an extreme, we generate now 1'000 random variables and add them to the model. We know that the estimated effect should not change when we add these variables, because they are independent of the participation decision and earnings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we generate the random variables, which are for simplicity all standard normal distributed. Then we merge the baseline characteristics, interaction terms, and random variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Total number of control variables: 1420\"\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "\n",
    "# Set starting value for replicability \n",
    "set.seed(123456) \n",
    "\n",
    "# Specify number of random variables\n",
    "cols <- 1000\n",
    "\n",
    "# Generate random variables\n",
    "redundant_x <- matrix(rnorm(nrow(df_int)*cols), nrow = nrow(df_int)) # We draw from a random standard normal distribution\n",
    "colnames(redundant_x) <- paste(\"Rand.\", 1:cols, sep=\"\")\n",
    "\n",
    "# Merge random variables with baseline characteritics and interaction terms\n",
    "df_rand <- as.data.frame(cbind(df_int, redundant_x))\n",
    "print(paste0(\"Total number of control variables: \", ncol(df_rand)-2))\n",
    "\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We estimate a multivariate OLS regression that controls for all baseline characteristics, interaction terms, and radom variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Univariate OLS Multivariate OLS1 Multivariate OLS2 Multivariate OLS3\n",
      "Estimate            12.50             16.29             19.16             23.75\n",
      "Std. Error           7.55              7.52              7.41              7.56\n",
      "Pr(>|t|)             0.10              0.03              0.01              0.00\n",
      "           Multivariate OLS4\n",
      "Estimate               20.03\n",
      "Std. Error              9.72\n",
      "Pr(>|t|)                0.04\n",
      "[1] \"Relative change in the estimated effect: -15.7%\"\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "\n",
    "## Multivariate OLS with all baseline characteristics, interaction terms, and random variables\n",
    "ols5 <- lm(EARNY4 ~ ., data = df_rand)\n",
    "\n",
    "## Store results\n",
    "results <- as.matrix(coef(summary(ols5))[2, c(\"Estimate\", \"Std. Error\", \"Pr(>|t|)\")])\n",
    "res[,5] <- results\n",
    "print(round(res, digits=2))\n",
    "\n",
    "## Relative change in the estimated effect\n",
    "print(paste0(\"Relative change in the estimated effect: \",round(100*(res[1,5]-res[1,4])/res[1,4], digits=1),\"%\"))\n",
    "\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding these randomly generated variables to the model should not affect the estimated effect at all, because the randomly generated variables are no confounders by construction. However, the effect size decreases by 15.7\\% and the standard errors increase by almost 30\\%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Play around with the seed and check how the estimated effects change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions:**\n",
    "\n",
    "- Adding relevant confounders increases the credibility of the identifying strategy.\n",
    "- However, it is difficult to determine the relevant control variables. Often economic theory is ambiguous and gives no clear guidance.\n",
    "- Particularly, it is difficult to identify the relvant interaction terms.\n",
    "- Seemingly, an attractive approach is to use a kitchen sink regression. But this approach can lead to inprecise estimates, which might lead to larger finite sample biases than omitted variables.\n",
    "- We face a trade-off between bias (too parsimonious model) and variance (too flexible model and redundant control variables)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Double-Selection Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **post-double-selection (PDS) procedure** of [Belloni, Chernozhukov, and Hansen (2014)](https://academic.oup.com/restud/article-abstract/81/2/608/1523757?redirectedFrom=fulltext) has three steps:\n",
    "\n",
    "1. Estimate the earnings equation $EARNY4 = \\gamma_1 + \\beta_1 \\cdot X + \\varepsilon$, excluding the participantion dummy, with Lasso.\n",
    "2. Estimate the participation probability $participation = \\gamma_2 + \\beta_2 \\cdot X + v$ with Lasso.\n",
    "3. Denote the union of all characteristics with non-zero coefficients in either $\\beta_1$ or $\\beta_2$ by $\\tilde{X}$. Estimate the Post-Lasso model \n",
    "\\begin{equation*}\n",
    "EARNY4 = \\gamma + \\delta \\cdot participation + \\beta \\cdot \\tilde{X} + u\n",
    "\\end{equation*}\n",
    "with OLS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short Recap Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lasso objective function is\n",
    "\n",
    "\\begin{equation*}\n",
    "\\min_{\\beta} \\left\\{ \\sum_{i=1}^{N} \\left( Y_i-  \\gamma -\\sum_{j=1}^{p}X_{ij}\\beta_j \\right)^2 + \\lambda \\sum_{j=1}^{p} |\\hat{l}_j \\beta_j| \\right\\},\n",
    "\\end{equation*}\n",
    "where $p$ are the number of observable characteristics. The Lasso minimizes the sum of squared residuals, subject to a penalty on the absolute size of the coefficients $\\beta_j$. The penalty term $\\lambda \\geq 0$ enables to regulate the degree of penalization. When $\\lambda=0$, there is no penalization and the Lasso and OLS estimates are similar. When $\\lambda>0$, some coefficients are shrunken towards zero and eventually approach zero excatly. When $\\lambda$ is very large, all coefficients are zero, excluding the constant $\\gamma$. The constant term is not penalized. When the coefficient $\\beta_j$ is zero, this is equivalent to omit the corresponding characterstic $X_j$ from the model. Accordingly, the Lasso is a model selection device. \n",
    "\n",
    "An important tuning parameter is the penalty term $\\lambda$. We consider two alternative ways of specifying the $\\lambda$:\n",
    "\n",
    "1. [Belloni et al. (2012)](https://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA9626) propose to use the theoretically derived optimal penalty term\n",
    "\\begin{equation*}\n",
    "\\displaystyle \\lambda = \\frac{2 c \\cdot \\Phi^{-1}\\left(\\frac{1-\\gamma}{2p} \\right)}{\\sqrt{N} }\n",
    "\\end{equation*}\n",
    "with the default values $c=1.1$ and $\\gamma = 0.1/log(N)$.\n",
    "\n",
    "2. Alteratively, we can use a cross-validation procedure the specify the optimal penalty term. We partition the sample into $k$ equally large folds and specify a grit of possible $\\lambda$ values (typically equispaced on a log-scale). We estimate the Lasso for a specific $\\lambda$ value in $k-1$ folds and extrapolate the fitted values to the retained fold. Then we calculate the model quality in the retained fold (e.g. using the MSE). We repeat this procedure k-times while alternating the retained fold. We calculate the average model quality across all folds. Then we repeat this procedure for all $\\lambda$ values on the grit. Finally, we select the $\\lambda$ value with the best average model quality. [Chetverikov, Liao, and Chernozhukov (2020)](https://arxiv.org/abs/1605.02214) provide the theoretical justification for the validty of this procedure.\n",
    "\n",
    "The penalty loadings $\\hat{l}_j$ can account for different scalings of the characteristics. The \"normal\" Lasso standardizes all characteristics before the estimation and set the penalty loadings to one. Alternatively, [Belloni et al. (2012)](https://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA9626) propose an iterative procedure to estimate the penalty loadings. When we use these penalty loading it is not required standardize the characteristics in the first place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Earnings Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "rlasso.default(x = as.matrix(df[, c(4:ncol(df))]), y = as.matrix(df$EARNY4), \n",
      "    penalty = list(homoscedastic = FALSE, c = 1.1, gamma = 0.1/log(N)))\n",
      "\n",
      "Post-Lasso Estimation:  TRUE \n",
      "\n",
      "Total number of variables: 33\n",
      "Number of selected variables: 10 \n",
      "\n",
      "Residuals: \n",
      "    Min      1Q  Median      3Q     Max \n",
      "-409.51 -137.34  -25.24   91.60 2038.03 \n",
      "\n",
      "            Estimate\n",
      "(Intercept)   202.56\n",
      "female        -61.71\n",
      "age_1           0.00\n",
      "age_2           0.00\n",
      "age_3           0.00\n",
      "ed0_6           0.00\n",
      "ed6_12          0.00\n",
      "hs_ged         46.27\n",
      "white          18.68\n",
      "black         -35.23\n",
      "hisp            0.00\n",
      "oth_eth         0.00\n",
      "haschld         0.00\n",
      "livespou        0.00\n",
      "everwork        0.00\n",
      "yr_work        38.84\n",
      "currjob        24.85\n",
      "job0_3          0.00\n",
      "job3_9          0.00\n",
      "job9_12        30.42\n",
      "earn1           0.00\n",
      "earn2           0.00\n",
      "earn3           0.00\n",
      "earn4          47.89\n",
      "badhlth         0.00\n",
      "welf_kid      -18.70\n",
      "got_fs          0.00\n",
      "publich         0.00\n",
      "got_afdc      -12.45\n",
      "harduse         0.00\n",
      "potuse          0.00\n",
      "evarrst         0.00\n",
      "pmsa            0.00\n",
      "msa             0.00\n",
      "\n",
      "Residual standard error: 194.3\n",
      "Multiple R-squared:  0.1057\n",
      "Adjusted R-squared:  0.1027\n",
      "Joint significance test:\n",
      " the sup score statistic for joint significance test is 990.1 with a p-value of     0\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "########################### Earnings Equation #################################\n",
    "###############################################################################\n",
    "\n",
    "# Predict earnings\n",
    "N <- nrow(df)\n",
    "st1 <- rlasso(as.matrix(df[,c(4:ncol(df))]), as.matrix(df$EARNY4), \n",
    "              penalty = list(homoscedastic = FALSE, c= 1.1, gamma = 0.1/log(N)))\n",
    "summary(st1)\n",
    "\n",
    "# Store selected variables\n",
    "n1<- names(st1$coefficients[(st1$coefficients != 0) == TRUE])[-1]\n",
    "\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Participation Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "rlasso.default(x = as.matrix(df[, c(4:ncol(df))]), y = as.matrix(df$participation), \n",
      "    penalty = list(homoscedastic = FALSE, c = 1.1, gamma = 0.1/log(N)))\n",
      "\n",
      "Post-Lasso Estimation:  TRUE \n",
      "\n",
      "Total number of variables: 33\n",
      "Number of selected variables: 0 \n",
      "\n",
      "Residuals: \n",
      "    Min      1Q  Median      3Q     Max \n",
      "-0.4417 -0.4417 -0.4417  0.5583  0.5583 \n",
      "\n",
      "          Estimate\n",
      "intercept        0\n",
      "female           0\n",
      "age_1            0\n",
      "age_2            0\n",
      "age_3            0\n",
      "ed0_6            0\n",
      "ed6_12           0\n",
      "hs_ged           0\n",
      "white            0\n",
      "black            0\n",
      "hisp             0\n",
      "oth_eth          0\n",
      "haschld          0\n",
      "livespou         0\n",
      "everwork         0\n",
      "yr_work          0\n",
      "currjob          0\n",
      "job0_3           0\n",
      "job3_9           0\n",
      "job9_12          0\n",
      "earn1            0\n",
      "earn2            0\n",
      "earn3            0\n",
      "earn4            0\n",
      "badhlth          0\n",
      "welf_kid         0\n",
      "got_fs           0\n",
      "publich          0\n",
      "got_afdc         0\n",
      "harduse          0\n",
      "potuse           0\n",
      "evarrst          0\n",
      "pmsa             0\n",
      "msa              0\n",
      "\n",
      "Residual standard error: 0.2467\n",
      "Multiple R-squared:      0\n",
      "Adjusted R-squared:      0\n",
      "Joint significance test:\n",
      " the sup score statistic for joint significance test is 0.7839 with a p-value of  0.02\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "######################### Participation Probability ###########################\n",
    "###############################################################################\n",
    "\n",
    "# Predict participation\n",
    "N <- nrow(df)\n",
    "st2 <- rlasso(as.matrix(df[,c(4:ncol(df))]), as.matrix(df$participation), \n",
    "              penalty = list(homoscedastic = FALSE, c= 1.1, gamma = 0.1/log(N)))\n",
    "summary(st2)\n",
    "\n",
    "# Store selected variables\n",
    "n2<- names(st2$coefficients[(st2$coefficients != 0) == TRUE])[-1]\n",
    "\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Post-Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = linear, data = df)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-402.49 -136.23  -22.38   92.46 2045.34 \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)    193.472     10.073  19.207  < 2e-16 ***\n",
       "participation   20.992      7.164   2.930  0.00342 ** \n",
       "female         -62.421      7.525  -8.295  < 2e-16 ***\n",
       "hs_ged          47.082      8.400   5.605 2.27e-08 ***\n",
       "white           18.586     10.080   1.844  0.06531 .  \n",
       "black          -35.516      8.799  -4.036 5.56e-05 ***\n",
       "yr_work         38.979      8.414   4.633 3.76e-06 ***\n",
       "currjob         24.415      9.935   2.457  0.01405 *  \n",
       "job9_12         31.098     10.444   2.977  0.00293 ** \n",
       "earn4           48.853     15.874   3.078  0.00211 ** \n",
       "welf_kid       -19.258      9.420  -2.044  0.04099 *  \n",
       "got_afdc       -12.498      8.364  -1.494  0.13522    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 194.3 on 2988 degrees of freedom\n",
       "Multiple R-squared:  0.1082,\tAdjusted R-squared:  0.105 \n",
       "F-statistic: 32.97 on 11 and 2988 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###############################################################################\n",
    "################################# Post-Lasso ##################################\n",
    "###############################################################################\n",
    "\n",
    "# Take union of selected covariates\n",
    "selected_covariates <- c(\"participation\", unique(c(n1, n2)))\n",
    "\n",
    "# Setup the formula of the linear regression model\n",
    "sumx <- paste(selected_covariates, collapse = \" + \")  \n",
    "linear <- paste(\"EARNY4\",paste(sumx, sep=\" + \"), sep=\" ~ \")\n",
    "linear <- as.formula(linear)\n",
    "\n",
    "# Post-Lasso regression\n",
    "ols <- lm(linear, data = df)\n",
    "summary(ols)\n",
    "\n",
    "# Heteroskedasticity robust standard errors\n",
    "#coeftest(ols, vcov = vcovHC(ols, type = \"HC1\"))\n",
    "\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Participation in Job Corps increased weekly earnings by 15.68 Dollars four years after the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Short-cut:** Estimate the Treatment Effect Directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"Estimates and significance testing of the effect of target variables\"\n",
       "   Estimate. Std. Error t value Pr(>|t|)   \n",
       "d1    20.992      7.179   2.924  0.00345 **\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###############################################################################\n",
    "################## Estimate the Treatment Effect Directly #####################\n",
    "###############################################################################\n",
    "\n",
    "# Post-Double-Selection Procedure \n",
    "dsp <- rlassoEffect(as.matrix(df[,c(4:ncol(df))]), as.matrix(df$EARNY4)\n",
    "          ,as.matrix(df$participation), model = TRUE, penalty = list(homoscedastic = FALSE), method = \"double selection\")\n",
    "summary(dsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Why do the standard errors of the manualy and automatically estimated treatment effect differ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**\n",
    "\n",
    "Estimate the post-doube-selection procedure using all baseline charactersitics, interaction terms, and randomly generated variables. How large is the effect of Job Corps participation on earnings? Which baseline and interaction terms are relevant for the Post-Lasso model? Do you have an economic interpretation for the selected variables? Does the post-doube-selection procedure omit the randomly generated variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Number of Selected Variables Earnings Equation: 13\"\n",
      " [1] \"female\"       \"hs_ged\"       \"black\"        \"Inter.V1V2\"   \"Inter.V1V18\" \n",
      " [6] \"Inter.V1V23\"  \"Inter.V1V25\"  \"Inter.V2V7\"   \"Inter.V7V25\"  \"Inter.V7V29\" \n",
      "[11] \"Inter.V12V13\" \"Inter.V13V14\" \"Inter.V13V17\"\n",
      "[1] \"Number of Selected Variables Participation Equation: 1\"\n",
      "[1] \"Inter.V11V21\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = linear, data = df_rand)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-352.77 -133.21  -24.22   91.99 2074.07 \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)   199.5642     8.6072  23.186  < 2e-16 ***\n",
       "participation  20.0628     7.1825   2.793 0.005251 ** \n",
       "female        -61.6600    10.0637  -6.127 1.01e-09 ***\n",
       "hs_ged         43.0018     8.8767   4.844 1.34e-06 ***\n",
       "black         -21.7701     9.7821  -2.226 0.026122 *  \n",
       "Inter.V1V2      1.3396    13.3594   0.100 0.920133    \n",
       "Inter.V1V18   -49.7426    17.7820  -2.797 0.005185 ** \n",
       "Inter.V1V23   -25.9714    13.1103  -1.981 0.047684 *  \n",
       "Inter.V1V25     0.3976    15.2702   0.026 0.979230    \n",
       "Inter.V2V7    -19.2962    12.1342  -1.590 0.111889    \n",
       "Inter.V7V25   -20.3661    13.3841  -1.522 0.128201    \n",
       "Inter.V7V29   -45.1147    12.1438  -3.715 0.000207 ***\n",
       "Inter.V12V13   45.0536     8.7290   5.161 2.61e-07 ***\n",
       "Inter.V13V14   26.0928     9.9273   2.628 0.008623 ** \n",
       "Inter.V13V17   39.0546    10.0647   3.880 0.000107 ***\n",
       "Inter.V11V21  -44.9504    36.8559  -1.220 0.222703    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 194.1 on 2984 degrees of freedom\n",
       "Multiple R-squared:  0.1117,\tAdjusted R-squared:  0.1072 \n",
       "F-statistic: 25.02 on 15 and 2984 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Earning Equation\n",
    "###############################################################################\n",
    "\n",
    "# Predict earnings\n",
    "st1 <- rlasso(as.matrix(df_rand[,c(3:ncol(df_rand))]), as.matrix(df$EARNY4))\n",
    "\n",
    "# Store selected variables\n",
    "n1<- names(st1$coefficients[(st1$coefficients != 0) == TRUE])[-1]\n",
    "print(paste0(\"Number of Selected Variables Earnings Equation: \",length(n1)))\n",
    "print(n1)\n",
    "\n",
    "###############################################################################\n",
    "# Participation Probability\n",
    "###############################################################################\n",
    "\n",
    "# Predict participation\n",
    "st2 <- rlasso(as.matrix(df_rand[,c(3:ncol(df_rand))]), as.matrix(df$participation))\n",
    "\n",
    "# Store selected variables\n",
    "n2<- names(st2$coefficients[(st2$coefficients != 0) == TRUE])[-1]\n",
    "print(paste0(\"Number of Selected Variables Participation Equation: \",length(n2)))\n",
    "print(n2)\n",
    "\n",
    "###############################################################################\n",
    "# Post-Lasso Model\n",
    "###############################################################################\n",
    "\n",
    "# Take union of selected covariates\n",
    "selected_covariates <- c(\"participation\", unique(c(n1, n2)))\n",
    "\n",
    "# Setup the formula of the linear regression model\n",
    "sumx <- paste(selected_covariates, collapse = \" + \")  \n",
    "linear <- paste(\"EARNY4\",paste(sumx, sep=\" + \"), sep=\" ~ \")\n",
    "linear <- as.formula(linear)\n",
    "\n",
    "# Post-Lasso OLS regression\n",
    "ols <- lm(linear, data = df_rand)\n",
    "summary(ols)\n",
    "\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers:**\n",
    "- Participation in Job Corps increased weekly earnings by 20.06 Dollars four years after the experiment. \n",
    "- The model includes interactions of *female* (V1) with *age\\_1* (V2), *earn1* (V18), *welf\\_kid* (V23), and *publich* (V25); *age\\_1* (V2) with *black* (V7); *black* (V7) with *publich* (V25) and *evarrst* (V29); *everwork* (V12) with *yr\\_work* (V13); *yr\\_work* (V13) with *currjob* (V14) and *job9\\_12* (V17); *livespou* (V11) with *earn4* (V21). \n",
    "- It is difficult to come up with an economic interpretation why exactly these interaction terms are selected. It is surprising that *haschld* is not selected.  We should resist the temptation to overinterpret the selected variables. Particularly, we should not interpret the coefficients of the control variables in a causal way.\n",
    "- The post-double-selection procedure does not select the randomly generated variables, which is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validated $\\lambda$ Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we specify the optimal $\\lambda$ value using a cross-validation procedure. For this purpose, we use the *glmnet* package.\n",
    "\n",
    "First, we select the relavant variables in the earnings equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAABNTU1oaGh8fHyM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\nEoAAiAQgACIBCPA/zXq519Nbq0UAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####################################################################\n",
    "################# Cross-Validated Lasso ############################\n",
    "####################################################################\n",
    "\n",
    "set.seed(123456789) # Starting value\n",
    "\n",
    "# Cross-validated Lasso in earnings equation\n",
    "lasso_earn <- cv.glmnet(as.matrix(df_int[,c(3:ncol(df_int))]), as.matrix(df$EARNY4), \n",
    "                        alpha=1, nfolds = 10, type.measure = 'mse', standardize = TRUE)\n",
    "# alpha =1 is Lasso, alpha = 0 is Ridgde\n",
    "# nfolds - number of cross-validation folds\n",
    "# type.measure - measure for model accuracy\n",
    "\n",
    "plot(lasso_earn)\n",
    "\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421 x 1 sparse Matrix of class \"dgCMatrix\"\n",
       "                      1\n",
       "(Intercept)  205.761212\n",
       "female       -32.939275\n",
       "age_1          .       \n",
       "age_3          .       \n",
       "ed0_6          .       \n",
       "ed6_12         .       \n",
       "hs_ged        10.473966\n",
       "black        -16.599278\n",
       "hisp           .       \n",
       "oth_eth        .       \n",
       "livespou       .       \n",
       "everwork       .       \n",
       "badhlth        .       \n",
       "welf_kid       .       \n",
       "got_fs         .       \n",
       "potuse         .       \n",
       "evarrst        .       \n",
       "pmsa           .       \n",
       "msa            .       \n",
       "Inter.V1V2     .       \n",
       "Inter.V1V3     .       \n",
       "Inter.V1V4     .       \n",
       "Inter.V1V5     .       \n",
       "Inter.V1V6     .       \n",
       "Inter.V1V7     .       \n",
       "Inter.V1V8     .       \n",
       "Inter.V1V9     .       \n",
       "Inter.V1V10    .       \n",
       "Inter.V1V11    .       \n",
       "Inter.V1V14    .       \n",
       "Inter.V1V15    .       \n",
       "Inter.V1V16    .       \n",
       "Inter.V1V17    .       \n",
       "Inter.V1V18    .       \n",
       "Inter.V1V19    .       \n",
       "Inter.V1V20    .       \n",
       "Inter.V1V21    .       \n",
       "Inter.V1V22    .       \n",
       "Inter.V1V23    .       \n",
       "Inter.V1V24    .       \n",
       "Inter.V1V25    .       \n",
       "Inter.V1V26    .       \n",
       "Inter.V1V27    .       \n",
       "Inter.V1V28    .       \n",
       "Inter.V1V29    .       \n",
       "Inter.V1V30    .       \n",
       "Inter.V1V31    .       \n",
       "Inter.V2V4     .       \n",
       "Inter.V2V5     .       \n",
       "Inter.V2V6     .       \n",
       "Inter.V2V7    -6.687385\n",
       "Inter.V2V8     .       \n",
       "Inter.V2V9     .       \n",
       "Inter.V2V10    .       \n",
       "Inter.V2V11    .       \n",
       "Inter.V2V12    .       \n",
       "Inter.V2V14    .       \n",
       "Inter.V2V15    .       \n",
       "Inter.V2V16    .       \n",
       "Inter.V2V17    .       \n",
       "Inter.V2V18    .       \n",
       "Inter.V2V19    .       \n",
       "Inter.V2V20    .       \n",
       "Inter.V2V21    .       \n",
       "Inter.V2V22    .       \n",
       "Inter.V2V23    .       \n",
       "Inter.V2V24    .       \n",
       "Inter.V2V25    .       \n",
       "Inter.V2V26    .       \n",
       "Inter.V2V27    .       \n",
       "Inter.V2V28    .       \n",
       "Inter.V2V29    .       \n",
       "Inter.V2V30    .       \n",
       "Inter.V2V31    .       \n",
       "Inter.V3V4     .       \n",
       "Inter.V3V5     .       \n",
       "Inter.V3V6     .       \n",
       "Inter.V3V7     .       \n",
       "Inter.V3V8     .       \n",
       "Inter.V3V9     .       \n",
       "Inter.V3V10    .       \n",
       "Inter.V3V11    .       \n",
       "Inter.V3V14    .       \n",
       "Inter.V3V15    .       \n",
       "Inter.V3V16    .       \n",
       "Inter.V3V17    .       \n",
       "Inter.V3V18    .       \n",
       "Inter.V3V19    .       \n",
       "Inter.V3V20    .       \n",
       "Inter.V3V21    .       \n",
       "Inter.V3V22    .       \n",
       "Inter.V3V23    .       \n",
       "Inter.V3V24    .       \n",
       "Inter.V3V25    .       \n",
       "Inter.V3V26    .       \n",
       "Inter.V3V27    .       \n",
       "Inter.V3V28    .       \n",
       "Inter.V3V29    .       \n",
       "Inter.V3V30    .       \n",
       "Inter.V3V31    .       \n",
       "Inter.V4V5     .       \n",
       "Inter.V4V6     .       \n",
       "Inter.V4V7     .       \n",
       "Inter.V4V8     .       \n",
       "Inter.V4V9     .       \n",
       "Inter.V4V10    .       \n",
       "Inter.V4V11    .       \n",
       "Inter.V4V14    .       \n",
       "Inter.V4V15    .       \n",
       "Inter.V4V16    .       \n",
       "Inter.V4V17    .       \n",
       "Inter.V4V18    .       \n",
       "Inter.V4V19    .       \n",
       "Inter.V4V20    .       \n",
       "Inter.V4V21    .       \n",
       "Inter.V4V22    .       \n",
       "Inter.V4V23    .       \n",
       "Inter.V4V24    .       \n",
       "Inter.V4V25    .       \n",
       "Inter.V4V26    .       \n",
       "Inter.V4V27    .       \n",
       "Inter.V4V28    .       \n",
       "Inter.V4V29    .       \n",
       "Inter.V4V30    .       \n",
       "Inter.V4V31    .       \n",
       "Inter.V5V6     .       \n",
       "Inter.V5V7     .       \n",
       "Inter.V5V8     .       \n",
       "Inter.V5V9     .       \n",
       "Inter.V5V10    .       \n",
       "Inter.V5V11    .       \n",
       "Inter.V5V14    .       \n",
       "Inter.V5V15    .       \n",
       "Inter.V5V16    .       \n",
       "Inter.V5V17    .       \n",
       "Inter.V5V18    .       \n",
       "Inter.V5V19    .       \n",
       "Inter.V5V20    .       \n",
       "Inter.V5V21    .       \n",
       "Inter.V5V22    .       \n",
       "Inter.V5V23    .       \n",
       "Inter.V5V24    .       \n",
       "Inter.V5V25    .       \n",
       "Inter.V5V26    .       \n",
       "Inter.V5V27    .       \n",
       "Inter.V5V28    .       \n",
       "Inter.V5V29    .       \n",
       "Inter.V5V30    .       \n",
       "Inter.V5V31    .       \n",
       "Inter.V6V7     .       \n",
       "Inter.V6V8     .       \n",
       "Inter.V6V9     .       \n",
       "Inter.V6V10    .       \n",
       "Inter.V6V11    .       \n",
       "Inter.V6V14    .       \n",
       "Inter.V6V15    .       \n",
       "Inter.V6V16    .       \n",
       "Inter.V6V17    .       \n",
       "Inter.V6V18    .       \n",
       "Inter.V6V19    .       \n",
       "Inter.V6V20    .       \n",
       "Inter.V6V21    .       \n",
       "Inter.V6V22    .       \n",
       "Inter.V6V23    .       \n",
       "Inter.V6V24    .       \n",
       "Inter.V6V25    .       \n",
       "Inter.V6V26    .       \n",
       "Inter.V6V27    .       \n",
       "Inter.V6V28    .       \n",
       "Inter.V6V29    .       \n",
       "Inter.V6V30    .       \n",
       "Inter.V6V31    .       \n",
       "Inter.V7V10    .       \n",
       "Inter.V7V11    .       \n",
       "Inter.V7V12    .       \n",
       "Inter.V7V14    .       \n",
       "Inter.V7V15    .       \n",
       "Inter.V7V16    .       \n",
       "Inter.V7V17    .       \n",
       "Inter.V7V18    .       \n",
       "Inter.V7V19    .       \n",
       "Inter.V7V20    .       \n",
       "Inter.V7V21    .       \n",
       "Inter.V7V22    .       \n",
       "Inter.V7V23    .       \n",
       "Inter.V7V24    .       \n",
       "Inter.V7V25    .       \n",
       "Inter.V7V26    .       \n",
       "Inter.V7V27    .       \n",
       "Inter.V7V28    .       \n",
       "Inter.V7V29   -1.467392\n",
       "Inter.V7V30    .       \n",
       "Inter.V7V31    .       \n",
       "Inter.V8V10    .       \n",
       "Inter.V8V11    .       \n",
       "Inter.V8V14    .       \n",
       "Inter.V8V15    .       \n",
       "Inter.V8V16    .       \n",
       "Inter.V8V17    .       \n",
       "Inter.V8V18    .       \n",
       "Inter.V8V19    .       \n",
       "Inter.V8V20    .       \n",
       "Inter.V8V21    7.697634\n",
       "Inter.V8V22    .       \n",
       "Inter.V8V23    .       \n",
       "Inter.V8V24    .       \n",
       "Inter.V8V25    .       \n",
       "Inter.V8V26    .       \n",
       "Inter.V8V27    .       \n",
       "Inter.V8V28    .       \n",
       "Inter.V8V29    .       \n",
       "Inter.V8V30    .       \n",
       "Inter.V8V31    .       \n",
       "Inter.V9V10    .       \n",
       "Inter.V9V11    .       \n",
       "Inter.V9V14    .       \n",
       "Inter.V9V15    .       \n",
       "Inter.V9V16    .       \n",
       "Inter.V9V17    .       \n",
       "Inter.V9V18    .       \n",
       "Inter.V9V19    .       \n",
       "Inter.V9V20    .       \n",
       "Inter.V9V21    .       \n",
       "Inter.V9V22    .       \n",
       "Inter.V9V23    .       \n",
       "Inter.V9V24    .       \n",
       "Inter.V9V25    .       \n",
       "Inter.V9V26    .       \n",
       "Inter.V9V27    .       \n",
       "Inter.V9V28    .       \n",
       "Inter.V9V29    .       \n",
       "Inter.V9V30    .       \n",
       "Inter.V9V31    .       \n",
       "Inter.V10V11   .       \n",
       "Inter.V10V14   .       \n",
       "Inter.V10V15   .       \n",
       "Inter.V10V16   .       \n",
       "Inter.V10V17   .       \n",
       "Inter.V10V18   .       \n",
       "Inter.V10V19   .       \n",
       "Inter.V10V20   .       \n",
       "Inter.V10V21   .       \n",
       "Inter.V10V22   .       \n",
       "Inter.V10V23   .       \n",
       "Inter.V10V25   .       \n",
       "Inter.V10V26   .       \n",
       "Inter.V10V27   .       \n",
       "Inter.V10V28   .       \n",
       "Inter.V10V29   .       \n",
       "Inter.V10V30   .       \n",
       "Inter.V10V31   .       \n",
       "Inter.V11V14   .       \n",
       "Inter.V11V15   .       \n",
       "Inter.V11V16   .       \n",
       "Inter.V11V17   .       \n",
       "Inter.V11V18   .       \n",
       "Inter.V11V19   .       \n",
       "Inter.V11V20   .       \n",
       "Inter.V11V21   .       \n",
       "Inter.V11V22   .       \n",
       "Inter.V11V23   .       \n",
       "Inter.V11V24   .       \n",
       "Inter.V11V25   .       \n",
       "Inter.V11V26   .       \n",
       "Inter.V11V27   .       \n",
       "Inter.V11V28   .       \n",
       "Inter.V11V29   .       \n",
       "Inter.V11V30   .       \n",
       "Inter.V11V31   .       \n",
       "Inter.V12V13  26.751069\n",
       "Inter.V12V24   .       \n",
       "Inter.V12V25   .       \n",
       "Inter.V12V26   .       \n",
       "Inter.V12V27   .       \n",
       "Inter.V13V14   2.668469\n",
       "Inter.V13V15   .       \n",
       "Inter.V13V16   .       \n",
       "Inter.V13V17  21.781869\n",
       "Inter.V13V19   .       \n",
       "Inter.V13V20   .       \n",
       "Inter.V14V15   .       \n",
       "Inter.V14V16   .       \n",
       "Inter.V14V17   .       \n",
       "Inter.V14V18   .       \n",
       "Inter.V14V19   .       \n",
       "Inter.V14V20   .       \n",
       "Inter.V14V21   .       \n",
       "Inter.V14V22   .       \n",
       "Inter.V14V23   .       \n",
       "Inter.V14V24   .       \n",
       "Inter.V14V25   .       \n",
       "Inter.V14V26   .       \n",
       "Inter.V14V27   .       \n",
       "Inter.V14V28   .       \n",
       "Inter.V14V29   .       \n",
       "Inter.V14V30   .       \n",
       "Inter.V14V31   .       \n",
       "Inter.V15V18   .       \n",
       "Inter.V15V19   .       \n",
       "Inter.V15V20   .       \n",
       "Inter.V15V22   .       \n",
       "Inter.V15V23   .       \n",
       "Inter.V15V24   .       \n",
       "Inter.V15V25   .       \n",
       "Inter.V15V26   .       \n",
       "Inter.V15V27   .       \n",
       "Inter.V15V28   .       \n",
       "Inter.V15V29   .       \n",
       "Inter.V15V30   .       \n",
       "Inter.V15V31   .       \n",
       "Inter.V16V17   .       \n",
       "Inter.V16V18   .       \n",
       "Inter.V16V19   .       \n",
       "Inter.V16V20   .       \n",
       "Inter.V16V21   .       \n",
       "Inter.V16V22   .       \n",
       "Inter.V16V23   .       \n",
       "Inter.V16V24   .       \n",
       "Inter.V16V25   .       \n",
       "Inter.V16V26   .       \n",
       "Inter.V16V27   .       \n",
       "Inter.V16V28   .       \n",
       "Inter.V16V29   .       \n",
       "Inter.V16V30   .       \n",
       "Inter.V16V31   .       \n",
       "Inter.V17V18   .       \n",
       "Inter.V17V19   .       \n",
       "Inter.V17V20   .       \n",
       "Inter.V17V21   6.075990\n",
       "Inter.V17V22   .       \n",
       "Inter.V17V23   .       \n",
       "Inter.V17V24   .       \n",
       "Inter.V17V25   .       \n",
       "Inter.V17V26   .       \n",
       "Inter.V17V27   .       \n",
       "Inter.V17V28   .       \n",
       "Inter.V17V29   .       \n",
       "Inter.V17V30   .       \n",
       "Inter.V17V31   .       \n",
       "Inter.V18V22   .       \n",
       "Inter.V18V23   .       \n",
       "Inter.V18V24   .       \n",
       "Inter.V18V25   .       \n",
       "Inter.V18V26   .       \n",
       "Inter.V18V27   .       \n",
       "Inter.V18V28   .       \n",
       "Inter.V18V29   .       \n",
       "Inter.V18V30   .       \n",
       "Inter.V18V31   .       \n",
       "Inter.V19V22   .       \n",
       "Inter.V19V23   .       \n",
       "Inter.V19V24   .       \n",
       "Inter.V19V25   .       \n",
       "Inter.V19V26   .       \n",
       "Inter.V19V27   .       \n",
       "Inter.V19V28   .       \n",
       "Inter.V19V29   .       \n",
       "Inter.V19V30   .       \n",
       "Inter.V19V31   .       \n",
       "Inter.V20V21   .       \n",
       "Inter.V20V22   .       \n",
       "Inter.V20V23   .       \n",
       "Inter.V20V24   .       \n",
       "Inter.V20V25   .       \n",
       "Inter.V20V26   .       \n",
       "Inter.V20V27   .       \n",
       "Inter.V20V28   .       \n",
       "Inter.V20V29   .       \n",
       "Inter.V20V30   .       \n",
       "Inter.V20V31   .       \n",
       "Inter.V21V22   .       \n",
       "Inter.V21V23   .       \n",
       "Inter.V21V24   .       \n",
       "Inter.V21V25   .       \n",
       "Inter.V21V26   .       \n",
       "Inter.V21V27   .       \n",
       "Inter.V21V28   .       \n",
       "Inter.V21V29   .       \n",
       "Inter.V21V30   .       \n",
       "Inter.V21V31   .       \n",
       "Inter.V22V23   .       \n",
       "Inter.V22V24   .       \n",
       "Inter.V22V25   .       \n",
       "Inter.V22V26   .       \n",
       "Inter.V22V27   .       \n",
       "Inter.V22V28   .       \n",
       "Inter.V22V29   .       \n",
       "Inter.V22V30   .       \n",
       "Inter.V22V31   .       \n",
       "Inter.V23V25   .       \n",
       "Inter.V23V26   .       \n",
       "Inter.V23V27   .       \n",
       "Inter.V23V28   .       \n",
       "Inter.V23V29   .       \n",
       "Inter.V23V30   .       \n",
       "Inter.V23V31   .       \n",
       "Inter.V24V25   .       \n",
       "Inter.V24V27   .       \n",
       "Inter.V24V28   .       \n",
       "Inter.V24V29   .       \n",
       "Inter.V24V30   .       \n",
       "Inter.V24V31   .       \n",
       "Inter.V25V26   .       \n",
       "Inter.V25V27   .       \n",
       "Inter.V25V28   .       \n",
       "Inter.V25V29   .       \n",
       "Inter.V25V30   .       \n",
       "Inter.V25V31   .       \n",
       "Inter.V26V27   .       \n",
       "Inter.V26V28   .       \n",
       "Inter.V26V29   .       \n",
       "Inter.V26V30   .       \n",
       "Inter.V26V31   .       \n",
       "Inter.V27V29   .       \n",
       "Inter.V27V30   .       \n",
       "Inter.V27V31   .       \n",
       "Inter.V28V29   .       \n",
       "Inter.V28V30   .       \n",
       "Inter.V28V31   .       \n",
       "Inter.V29V30   .       \n",
       "Inter.V29V31   .       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####################################################################\n",
    "\n",
    "# Plot Lasso coefficients\n",
    "coef(lasso_earn,s = lasso_earn$lambda.1se) \n",
    "# $lambda.min - Lambda that minimizes cross-validated MSE\n",
    "# $lambda.1se - Lambda of 1 standard error rule\n",
    "\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Number of Selected Variables Earnings Equation: 78\"\n",
      "[1] \"Selected Variables:\"\n",
      " [1] \"female\"       \"hs_ged\"       \"black\"        \"everwork\"     \"badhlth\"     \n",
      " [6] \"potuse\"       \"Inter.V1V9\"   \"Inter.V1V18\"  \"Inter.V1V20\"  \"Inter.V1V23\" \n",
      "[11] \"Inter.V2V6\"   \"Inter.V2V7\"   \"Inter.V2V8\"   \"Inter.V2V14\"  \"Inter.V2V20\" \n",
      "[16] \"Inter.V2V26\"  \"Inter.V2V27\"  \"Inter.V2V30\"  \"Inter.V3V6\"   \"Inter.V3V11\" \n",
      "[21] \"Inter.V3V18\"  \"Inter.V3V20\"  \"Inter.V4V6\"   \"Inter.V4V10\"  \"Inter.V4V15\" \n",
      "[26] \"Inter.V4V22\"  \"Inter.V4V27\"  \"Inter.V5V17\"  \"Inter.V5V19\"  \"Inter.V5V27\" \n",
      "[31] \"Inter.V5V31\"  \"Inter.V6V7\"   \"Inter.V6V16\"  \"Inter.V6V21\"  \"Inter.V6V30\" \n",
      "[36] \"Inter.V7V25\"  \"Inter.V7V29\"  \"Inter.V7V30\"  \"Inter.V8V17\"  \"Inter.V8V18\" \n",
      "[41] \"Inter.V8V21\"  \"Inter.V8V23\"  \"Inter.V9V10\"  \"Inter.V9V14\"  \"Inter.V9V23\" \n",
      "[46] \"Inter.V9V26\"  \"Inter.V9V27\"  \"Inter.V9V28\"  \"Inter.V9V30\"  \"Inter.V10V16\"\n",
      "[51] \"Inter.V10V19\" \"Inter.V10V21\" \"Inter.V10V29\" \"Inter.V10V30\" \"Inter.V11V16\"\n",
      "[56] \"Inter.V11V21\" \"Inter.V11V28\" \"Inter.V12V13\" \"Inter.V14V17\" \"Inter.V14V31\"\n",
      "[61] \"Inter.V15V18\" \"Inter.V15V22\" \"Inter.V15V27\" \"Inter.V15V28\" \"Inter.V16V17\"\n",
      "[66] \"Inter.V16V26\" \"Inter.V17V21\" \"Inter.V17V30\" \"Inter.V18V22\" \"Inter.V18V28\"\n",
      "[71] \"Inter.V20V21\" \"Inter.V20V30\" \"Inter.V21V24\" \"Inter.V22V23\" \"Inter.V22V26\"\n",
      "[76] \"Inter.V22V28\" \"Inter.V22V31\" \"Inter.V24V25\"\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "\n",
    "# Select covariates with non-zero coefficients\n",
    "coef <- predict(lasso_earn,s = lasso_earn$lambda.min, type = \"nonzero\") #\n",
    "colnames <- colnames(df_int[,c(3:ncol(df_int))])\n",
    "n1 <- colnames[unlist(coef)]\n",
    "print(paste0(\"Number of Selected Variables Earnings Equation: \",length(n1)))\n",
    "print(\"Selected Variables:\")\n",
    "print(n1)\n",
    "\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**\n",
    "\n",
    "Select the relevant variables in the participation equation using a cross-validated Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAABNTU1oaGh8fHyM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\nQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####################################################################\n",
    "\n",
    "set.seed(123456789) # Starting value\n",
    "\n",
    "# Cross-validated Lasso in participation equation\n",
    "lasso_part <- cv.glmnet(as.matrix(df_int[,c(3:ncol(df_int))]), as.matrix(df$participation), \n",
    "                        alpha=1, nfolds = 10, type.measure = 'mse', standardize = TRUE)\n",
    "plot(lasso_part)\n",
    "\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Number of Selected Variables Participation Equation: 24\"\n",
      "[1] \"Selected Variables:\"\n",
      " [1] \"Inter.V1V2\"   \"Inter.V1V9\"   \"Inter.V2V7\"   \"Inter.V2V25\"  \"Inter.V3V4\"  \n",
      " [6] \"Inter.V3V10\"  \"Inter.V3V17\"  \"Inter.V4V5\"   \"Inter.V4V11\"  \"Inter.V4V20\" \n",
      "[11] \"Inter.V4V29\"  \"Inter.V4V31\"  \"Inter.V5V26\"  \"Inter.V6V28\"  \"Inter.V9V22\" \n",
      "[16] \"Inter.V11V17\" \"Inter.V11V21\" \"Inter.V15V23\" \"Inter.V19V28\" \"Inter.V19V29\"\n",
      "[21] \"Inter.V20V27\" \"Inter.V20V30\" \"Inter.V21V30\" \"Inter.V24V25\"\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "\n",
    "# Select covariates with non-zero coefficients\n",
    "coef <- predict(lasso_part,s = lasso_part$lambda.min, type = \"nonzero\") #\n",
    "colnames <- colnames(df_int[,c(3:ncol(df_int))])\n",
    "n2 <- colnames[unlist(coef)]\n",
    "print(paste0(\"Number of Selected Variables Participation Equation: \",length(n2)))\n",
    "print(\"Selected Variables:\")\n",
    "print(n2)\n",
    "\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**\n",
    "\n",
    "Take the union of variables with non-zero coefficients in either the earnings or participation equation. Estimate the effect of participation on earning controlling for the union of selected variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = linear, data = df_int)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-511.28 -128.88  -23.90   92.92 1677.78 \n",
       "\n",
       "Coefficients:\n",
       "                Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)    218.80638   12.28001  17.818  < 2e-16 ***\n",
       "participation   20.72125    7.17460   2.888 0.003904 ** \n",
       "female         -61.31100   11.20325  -5.473 4.81e-08 ***\n",
       "hs_ged         -26.27552   18.53056  -1.418 0.156311    \n",
       "black          -35.83871   13.51715  -2.651 0.008061 ** \n",
       "everwork         9.21773   12.02832   0.766 0.443539    \n",
       "badhlth          8.08855   20.62032   0.392 0.694894    \n",
       "potuse         -12.99586   12.22145  -1.063 0.287705    \n",
       "Inter.V1V9      -8.23635   26.59041  -0.310 0.756774    \n",
       "Inter.V1V18    -24.71654   22.30324  -1.108 0.267866    \n",
       "Inter.V1V20     10.49933   20.14330   0.521 0.602245    \n",
       "Inter.V1V23     -4.79037   14.59134  -0.328 0.742707    \n",
       "Inter.V2V6      78.14523   33.93048   2.303 0.021344 *  \n",
       "Inter.V2V7     -17.49387   15.02489  -1.164 0.244388    \n",
       "Inter.V2V8     -43.70538   18.86822  -2.316 0.020609 *  \n",
       "Inter.V2V14     22.44440   16.60156   1.352 0.176498    \n",
       "Inter.V2V20     40.33782   25.13801   1.605 0.108679    \n",
       "Inter.V2V26    -10.42285   15.04353  -0.693 0.488462    \n",
       "Inter.V2V27     35.91529   30.50183   1.177 0.239101    \n",
       "Inter.V2V30     -0.28240   14.82567  -0.019 0.984804    \n",
       "Inter.V3V6      39.10951   17.25053   2.267 0.023454 *  \n",
       "Inter.V3V11    -19.17596   24.96670  -0.768 0.442513    \n",
       "Inter.V3V18    -35.24064   32.16878  -1.095 0.273392    \n",
       "Inter.V3V20     56.19659   21.94849   2.560 0.010506 *  \n",
       "Inter.V4V6       9.31323   19.16362   0.486 0.627014    \n",
       "Inter.V4V10     22.34223   19.55860   1.142 0.253414    \n",
       "Inter.V4V15     40.41525   18.64892   2.167 0.030304 *  \n",
       "Inter.V4V22    -22.02425   22.62781  -0.973 0.330472    \n",
       "Inter.V4V27   -112.03118   35.49609  -3.156 0.001615 ** \n",
       "Inter.V5V17     18.75659   17.48349   1.073 0.283442    \n",
       "Inter.V5V19     18.81351   14.37041   1.309 0.190576    \n",
       "Inter.V5V27      2.48738   35.28167   0.071 0.943800    \n",
       "Inter.V5V31     16.51406   12.65488   1.305 0.192011    \n",
       "Inter.V6V7      26.48871   17.55713   1.509 0.131481    \n",
       "Inter.V6V16     39.19575   16.90622   2.318 0.020496 *  \n",
       "Inter.V6V21     38.08072   28.10720   1.355 0.175574    \n",
       "Inter.V6V30     17.78363   17.48273   1.017 0.309138    \n",
       "Inter.V7V25    -16.63007   14.92638  -1.114 0.265311    \n",
       "Inter.V7V29    -53.01763   13.92922  -3.806 0.000144 ***\n",
       "Inter.V7V30    -23.28081   14.11808  -1.649 0.099254 .  \n",
       "Inter.V8V17      7.65045   25.44055   0.301 0.763651    \n",
       "Inter.V8V18    -27.98130   30.32543  -0.923 0.356240    \n",
       "Inter.V8V21    120.93004   44.37055   2.725 0.006460 ** \n",
       "Inter.V8V23    -37.64934   22.10452  -1.703 0.088630 .  \n",
       "Inter.V9V10    -28.92605   39.93991  -0.724 0.468977    \n",
       "Inter.V9V14    -71.50703   33.30715  -2.147 0.031884 *  \n",
       "Inter.V9V23    -68.08846   37.04008  -1.838 0.066130 .  \n",
       "Inter.V9V26    -14.09715   31.54051  -0.447 0.654942    \n",
       "Inter.V9V27    -79.18762   46.76726  -1.693 0.090519 .  \n",
       "Inter.V9V28    -48.17738   31.16486  -1.546 0.122241    \n",
       "Inter.V9V30     63.38105   28.09505   2.256 0.024148 *  \n",
       "Inter.V10V16   -39.79621   21.89534  -1.818 0.069234 .  \n",
       "Inter.V10V19   -29.99707   21.45820  -1.398 0.162241    \n",
       "Inter.V10V21    91.20934   36.10492   2.526 0.011582 *  \n",
       "Inter.V10V29    45.18782   19.67347   2.297 0.021696 *  \n",
       "Inter.V10V30    41.76639   17.66203   2.365 0.018107 *  \n",
       "Inter.V11V16   -31.55682   29.88864  -1.056 0.291141    \n",
       "Inter.V11V21  -188.81560   51.99711  -3.631 0.000287 ***\n",
       "Inter.V11V28   -55.21420   38.24788  -1.444 0.148963    \n",
       "Inter.V12V13    28.54795   14.14705   2.018 0.043689 *  \n",
       "Inter.V14V17    -1.14292   17.22301  -0.066 0.947096    \n",
       "Inter.V14V31    43.49615   15.72329   2.766 0.005705 ** \n",
       "Inter.V15V18    -7.25566   19.92198  -0.364 0.715732    \n",
       "Inter.V15V22    -6.44266   29.81261  -0.216 0.828921    \n",
       "Inter.V15V27    53.24873   35.02813   1.520 0.128577    \n",
       "Inter.V15V28    -5.37644   22.34990  -0.241 0.809915    \n",
       "Inter.V16V17   -29.66553   22.54969  -1.316 0.188425    \n",
       "Inter.V16V26    -7.84453   15.60910  -0.503 0.615311    \n",
       "Inter.V17V21    31.70590   24.86649   1.275 0.202395    \n",
       "Inter.V17V30    44.60477   22.32368   1.998 0.045800 *  \n",
       "Inter.V18V22   -12.33053   40.55461  -0.304 0.761113    \n",
       "Inter.V18V28   -12.38897   31.37652  -0.395 0.692984    \n",
       "Inter.V20V21  -301.59813  204.23680  -1.477 0.139862    \n",
       "Inter.V20V30    11.98263   24.31755   0.493 0.622222    \n",
       "Inter.V21V24    39.91097   34.49498   1.157 0.247364    \n",
       "Inter.V22V23   -11.07078   25.09679  -0.441 0.659157    \n",
       "Inter.V22V26     1.22723   22.71224   0.054 0.956912    \n",
       "Inter.V22V28   -17.07931   23.23860  -0.735 0.462427    \n",
       "Inter.V22V31   -22.46175   20.34275  -1.104 0.269613    \n",
       "Inter.V24V25    -3.89718   14.27968  -0.273 0.784936    \n",
       "Inter.V1V2      -6.24421   14.88342  -0.420 0.674851    \n",
       "Inter.V2V25      2.14755   16.11247   0.133 0.893977    \n",
       "Inter.V3V4      -1.17815   19.46305  -0.061 0.951736    \n",
       "Inter.V3V10    -17.93547   16.03008  -1.119 0.263291    \n",
       "Inter.V3V17    -19.77295   19.63570  -1.007 0.314024    \n",
       "Inter.V4V5     -54.06674   97.17493  -0.556 0.577990    \n",
       "Inter.V4V11    -10.98506   30.93465  -0.355 0.722536    \n",
       "Inter.V4V20      0.78464   22.70072   0.035 0.972430    \n",
       "Inter.V4V29     -8.89651   16.31786  -0.545 0.585657    \n",
       "Inter.V4V31     15.19315   13.23985   1.148 0.251256    \n",
       "Inter.V5V26     -2.93411   15.13696  -0.194 0.846317    \n",
       "Inter.V6V28      1.45287   21.56807   0.067 0.946298    \n",
       "Inter.V9V22     -6.11602   40.19272  -0.152 0.879066    \n",
       "Inter.V11V17    65.59429   35.51909   1.847 0.064888 .  \n",
       "Inter.V15V23     1.94033   19.36003   0.100 0.920174    \n",
       "Inter.V19V28    -0.02794   18.48550  -0.002 0.998794    \n",
       "Inter.V19V29    22.77065   17.52307   1.299 0.193887    \n",
       "Inter.V20V27    -5.74021   43.99378  -0.130 0.896198    \n",
       "Inter.V21V30     2.61494   33.63697   0.078 0.938040    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 189.5 on 2901 degrees of freedom\n",
       "Multiple R-squared:  0.1767,\tAdjusted R-squared:  0.1489 \n",
       "F-statistic: 6.354 on 98 and 2901 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Post-Lasso Model\n",
    "###############################################################################\n",
    "\n",
    "# Take union of selected covariates\n",
    "selected_covariates <- c(\"participation\", unique(c(n1, n2)))\n",
    "\n",
    "# Setup the formula of the linear regression model\n",
    "sumx <- paste(selected_covariates, collapse = \" + \")  \n",
    "linear <- paste(\"EARNY4\",paste(sumx, sep=\" + \"), sep=\" ~ \")\n",
    "linear <- as.formula(linear)\n",
    "\n",
    "# Post-Lasso OLS regression\n",
    "ols <- lm(linear, data = df_int)\n",
    "summary(ols)\n",
    "\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises:**\n",
    "\n",
    "1. Estimate the effect of participation on earnings using the one-standard-error rule to select the relevant charateristics with the Lasso.\n",
    "2. Estimate the effect of participation on earnings using five instead of ten folds for the cross-validation procedure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
